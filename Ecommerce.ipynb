{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "aAZRlPo-7L6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('AI_Project_ecommerceDataset.csv')\n",
        "#df.head()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "JS15U73PtfQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean Dataset**"
      ],
      "metadata": {
        "id": "JDrurja6nHEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'] = df['description']\n",
        "df.isnull().sum()\n",
        "df['description'] = df['description'].fillna('')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lJo5euCH4lGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Labels Information**"
      ],
      "metadata": {
        "id": "JLyzDzE_nSIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_count = df['category'].nunique()\n",
        "print(\"Total Label =\",labels_count)\n",
        "print(\"\\n\")\n",
        "labels = df['category'].unique()\n",
        "print(\"Labels =\",labels)"
      ],
      "metadata": {
        "id": "3OX-wOvLEeZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "97Q3hLDaDS3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "gvm2Pduvy-B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    tokens = [token.text for token in doc if not token.is_stop]\n",
        "    tokens = [token for token in tokens if token not in string.punctuation]\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "    lemmatized_tokens = [token for token in lemmatized_tokens if token.isalpha()]\n",
        "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return preprocessed_text"
      ],
      "metadata": {
        "id": "4EqbWEAOyV7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total 50425 datasets, so it takes too much times for run\n",
        "df['description'] = df['description'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "rI-e2HgGyyJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label Encoding**"
      ],
      "metadata": {
        "id": "J6xiPgKWIHKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['category'] = label_encoder.fit_transform(df['category'])\n",
        "df['category']"
      ],
      "metadata": {
        "id": "Q_0Y-xWBIGa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "ZksG0poUDbQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df['description'])\n",
        "Y = df['category']\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "HZYHQboIB4F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Text Split**"
      ],
      "metadata": {
        "id": "XNAPRQLXD1Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "oAfqFMkUtlHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "lr = LogisticRegression(solver = 'saga')\n",
        "lr = lr.fit(X_train,Y_train)\n",
        "lr_pred = lr.predict(X_test)\n",
        "print(accuracy_score(Y_test, lr_pred))"
      ],
      "metadata": {
        "id": "5rMnvNAdkan4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"\\t***Train-Test Accuracy***\")\n",
        "print(\"\\n\")\n",
        "LR = LogisticRegression(solver = 'saga') # 'lbfgs=0.9683', 'newton-cg=0.9683', 'sag=0.9683', 'liblinear=0.964', 'saga=0.9685'\n",
        "LR_Model=LR.fit(X_train,Y_train)\n",
        "LR_prediction =LR_Model.predict(X_test)\n",
        "print(\"Logistic Regression Train Accuracy :\", accuracy_score(Y_train,LR_Model.predict(X_train)))\n",
        "print(\"Logistic Regression Test Accuracy  :\", accuracy_score(Y_test, LR_prediction))"
      ],
      "metadata": {
        "id": "H6gJNqXUZZ8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test Classification Report\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"\\t***Train-Test Classification Report***\")\n",
        "print(\"\\n\")\n",
        "print(classification_report(Y_test, LR_prediction))\n",
        "print(\"\\n\")\n",
        "print(\"\\t***Train-Test Classification Report Display***\")\n",
        "print(\"\\n\")\n",
        "plt.figure(figsize=(4, 2))\n",
        "viz = ClassificationReport(LogisticRegression(solver = 'saga'), cmap='Oranges') #colors\n",
        "viz.fit(X_train, Y_train)\n",
        "viz.score(X_test, Y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "NBBDDWNQZZ-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"\\t***Train-Test Confusion Matrix***\")\n",
        "print(\"\\n\")\n",
        "LR = confusion_matrix(Y_test, LR_prediction)\n",
        "print(confusion_matrix(Y_test, LR_prediction))\n",
        "print(\"\\n\")\n",
        "# Display\n",
        "print(\"\\t***Train-Test Confusion Matrix Display***\")\n",
        "print(\"\\n\")\n",
        "fig, ax = plot_confusion_matrix(conf_mat=LR,cmap='Oranges', class_names=labels, figsize=(3, 3))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-WJnrn1HZ6Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 Fold Cross Validation Accuracy\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "print(\"\\t***Cross Validation Accuracy***\")\n",
        "print(\"\\n\")\n",
        "LR = LogisticRegression(solver = 'saga')\n",
        "scores = cross_val_score(LR, X, Y, cv=10) #CV means K\n",
        "print(scores)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "metadata": {
        "id": "qdRX2rTHaLmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 CV Classification Report\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\t***Cross validation Classification Report***\")\n",
        "print(\"\\n\")\n",
        "predicted = cross_val_predict(LR, X, Y, cv=10)\n",
        "print(classification_report(Y, predicted))"
      ],
      "metadata": {
        "id": "dR-mNpmsaRrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 CV Confusion Matrix\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(\"\\t***Cross validation Confusion Matrix***\")\n",
        "print(\"\\n\")\n",
        "predicted = cross_val_predict(LR, X, Y, cv=10)\n",
        "conf_matrix = confusion_matrix(Y, predicted)\n",
        "print(conf_matrix)\n",
        "print(\"\\n\")\n",
        "# Display\n",
        "print(\"\\t***Cross validation Confusion Matrix Display***\")\n",
        "print(\"\\n\")\n",
        "plt.figure(figsize=(4, 2))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cO0R3YnLaPMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nq1fgK3coSYr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}